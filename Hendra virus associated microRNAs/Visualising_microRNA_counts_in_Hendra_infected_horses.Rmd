---
title: Mining the transcriptome for biomarkers of infection 
subtitle: A call for larger sample sizes 
author:  Marina Alexander
affiliation: Health & Biosecurity| Managing invasive species and Disease
photo: resources/img/Measles.jpg

short_title: Optional short title

output: DSreport::project_summary
---
```{r setup, include=FALSE}
#Remind R where to look for libraries
.libPaths(c("C:/Users/ale097/Data School/Packages"))
#Load libraries
library(tidyverse)
library(gapminder)
library(kableExtra)
library(knitr)
library(edgeR)
library(limma)

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(
  results = 'asis',
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = 'center'
)

```


# Introduction
Hi my name is Marina. I work on viruses. Before data school I would typically enter my data into Excel or Prism to make bar graphs with errors bars, then communicate these in publications and powerpoint slides. Using R, I can now reproducibly wrangle data imported from Excel, plot with ggplot2 to make really flexible and informative visualisations of the raw data. This has helped me to understand the sources of variation in my data, apply appropriate statistics and make novel visualisations.  

# My Project
My group are looking to find microRNAs that are predictive of viral infection. Such microRNAs could act as early bio-markers of infection. Allowing us to isolate the infected individual before they show signs of infection.  To identify these microRNAs we set up an experiment in which three horses were infected with Hendra virus and blood was taken at day 0, 1, 3, 5 and 7. RNA was extracted and sequenced, many millions of sequencing reads were then aligned to the 800+ currently defined microRNAs in the horse genome. This process generates a table where the number of aligned reads for each microRNA are counted for each sample. My goal was to model a relationship between microRNA expression level and time since infection using multi-linear regression.

<style>
.column-left{
  float: left;
  width: 25%;
  text-align: left;
}
.column-center{
  display: inline-block;
  width: 60%;
  text-align: center;
}
.column-right{
  float: right;
  width: 15%;
  text-align: right;
}
</style>

<div class="column-left">
</br>
I began with two tables, one a count matrix for each microRNA and the other a table containing metadata. 
</br>
</br>
There are some challenging apsects to this data.
</br>
* 800+ microRNAs
</br>
* microRNAs with zero counts
</br>
* Sample 6 did not work 
</br>
* High dynamic range of counts 
</div>

<div class="column-center">
```{r reading_in_data, out.width='100%', echo = FALSE, results ='hide'}
read_csv("data/Redlands_counts.csv")   
microRNA_counts <- read_csv("data/Redlands_counts.csv")
```

Snippet of microRNA counts
```{r counts_table, out.width='100%', echo = FALSE}
knitr::kable(head(microRNA_counts[1:8], n =6), format = "html") %>% 
  kable_styling("striped", full_width = FALSE)

```
</div>

<div class="column-right">
```{r reading_in_metadata, out.width = '100%', echo = FALSE, results = 'hide'}
read_csv("data/redlands_horse_metadata.csv")                            
redlands_horse_metadata <- read_csv("data/redlands_horse_metadata.csv")
```
Snippet of metadata
```{r metadata_table, out.width = '100%', echo = FALSE}

knitr::kable(head(redlands_horse_metadata, n = 6 ), format = "html") %>% 
  kable_styling("striped", full_width = FALSE)

```
</div>

## Data clean up
I used tidyverse and edgeR packages to clean up my RNA-seq count data. After removing s6, we create what's called a DGEList where raw counts are converted to counts per million (CPM) to account for the different sample or library sizes.

```{r tidying data for plotting, out.width = '100%', echo = FALSE, results = 'hide'}
redlands_horse_metadata_tidy <- redlands_horse_metadata %>% 
  mutate(day = sub("d","", condition )) %>%
  mutate(day = as.numeric(day)) %>%
  select(-condition) 

lib_size <- microRNA_counts %>%
  gather(sample, counts, -gene) %>% 
  left_join(redlands_horse_metadata_tidy, by = "sample") %>% 
  rename(library = sample) %>% 
  mutate(library = sub("s","", library)) %>% 
  mutate(counts_million = counts/1000000) %>% 
  group_by(library) %>% 
  summarise(counts_sum = sum(counts_million))

mean(lib_size$counts_sum)
```

```{r plotting library size, out.width = '50%', echo = FALSE }
microRNA_counts %>%
  gather(sample, counts, -gene) %>% 
  left_join(redlands_horse_metadata_tidy, by = "sample") %>% 
  rename(library = sample) %>% 
  mutate(library = sub("s","", library)) %>%
  mutate(counts_million = counts/1000000) %>% 
  full_join(lib_size, by = "library") %>%
  ggplot(aes(y = counts_sum, x = library, color = day, shape = animal)) +
  geom_point(size = 5) +
  geom_hline(yintercept=1.661439, linetype="dashed", color = "red") +
  scale_x_discrete(limits = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)) +
  labs( x = "sample", 
        y = "Library size (millions)")
```

```{r creating a DGEList, out.width = '100%', echo = FALSE, results = 'hide'}
microRNA_counts_s6 <- microRNA_counts %>% 
  select(-s6)

redlands_horse_metadata_s6 <- redlands_horse_metadata %>% 
  filter(sample != "s6")

horse_counts <- DGEList(counts = microRNA_counts_s6[, -1], genes = microRNA_counts_s6[, 1], samples = redlands_horse_metadata_s6)
```

```{r filtering lowly expressed genes, out.width = '100%', echo = FALSE, results = 'hide'}
design_matrix <- model.matrix(~ condition + animal, data = redlands_horse_metadata)

gene_filter <- filterByExpr(horse_counts, min.count = 0.5, min.total.count = 20, design = design_matrix)

horse_filtered <- horse_counts[gene_filter, , keep.lib.sizes = FALSE]

horse_filtered
```



**Tables**
I wanted to perform PCA on these samples to identify samples with similar expression profiles. Do the horses differ significantly? 
**Images from a file**

# My Digital Toolbox

What digital tools have you been using in your project? Which ones have you learned since starting 
Data School?

You can use all the usual R markdown features in writing a project summary, including lists:

* R - dplyr, ggplot, ...
* Python
* SQL

![](resources/img/tidyverse.png){width=100px}
![](resources/img/edgeR.png){width=270px}
![](https://raw.githubusercontent.com/tidyverse/ggplot2/master/man/figures/logo.png){.pull-right width=100px}

**Plots from R**
```{r standard-plot, out.width='60%', fig.align='center', fig.height= 4, fig.width=6, fig.cap="Yet another gapminder plot"}

```

Your figure and table captions are automatically numbered and can be referenced in the text
if needed: see eg. Table \@ref(tab:mytable) and Figure \@ref(fig:standard-plot)



## Favourite tool (optional)

Is there a tool/package/function in particular that you've enjoyed using? Give it a special shout out here.



No prizes for guessing mine:

# My time went ...

What parts of the project took the most time and effort? Were there any surprising challenges you
encountered, and how did you solve them?

# Next steps

What further steps do you wish your project could take? Or are there any new digital skills that you
are keen to develop as a result of your involvement in the Data School?

# My Data School Experience

This poster is mostly about your synthesis project. However we would also like to hear about other
parts of your Data School experience. What aspects of the program did you really enjoy? How have you
been applying the skills you have learned in your daily work? Have you been able to transfer this 
knowledge to your team members? Concrete examples demonstrating this would be useful here
(meetings/talks/collaborations/new roles). Any descriptions of the personal impact the program has 
had are welcome here as well!
